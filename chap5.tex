%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Reactivity Experiments}
\section{Methods} [Pretty rudimentary description of Das's process]
Das Lab at Stanford perform chemical mapping experiments on RNA
molecules. An RNA strand of interest is selected and is from there on
called the wildtype strand (abbreviated WT). Then for each nucleotide
in the strand a mutant is created switching out that particular base
with its Watson and Crick opposite. This is intended to perturb the
energy landscape in such a way that dominant loops may become less
prominent and other foldings become more stable. SHAPE analysis is
then done on each strand to prob which bases are paired and which are
not.

Data was obtained in the form of RDat files from Stanford's RNA
mapping database. SHAPE reactivity is extracted from these files for
the WT and each of its mutants. To normalize the reactivity trace of a
strand to a probability on $[0, 1]$ first the partition function is
calculated for this strand, then probability of each base being paired
is computed using the formula

$$ base pair formula ,$$

and finally these probabilities are rank sorted and fitted to a fermi
distribution using a least squares gradient decent fit [figure
here]. We believe that the measured reactivity should relate
[correlate, correspond?] to the probability that a base is unpaired,
so the reactivities are reverse rank sorted and mapped to the fermi
distribution found by our fit.

From here, using the assumption that each mutation changes the
relative energies of each macrostate without changing their internal
structures, we fit this data to a model of $k$ clusters each with $n$
nucleotide probabilities, with then $k*(n+1)$ cluster
probabilities. Therefore we have a model with $k(2*n + 1)$ paramters
fitting to $n*(n+1)$ data entries. A boxed gradient decent is used to
minimize a cost function:

$ Cost function $

This fit results in $k$ fitted clusters with $k*(n+1)$ cluster
probabilities.

These fitted clusters are compared to $k$ nests generated by
Nestor. The nests are created using the methods desribed in [Nestor
chapter] for each strand. Since these nests are created independant of
any other strands, nests for different strands must be matched to each
other in order to compare to the fitted clusters.

[paragraph on the matching process, still investigating]

Once these matches are made we can compare the cluster vs nest
probabilites for the WT and each mutant and see how they correlate, as
well as investigate other clusters that may be found.
