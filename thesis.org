Title: RNA macrostates: Theory and Verification
Summary: Fast stochastic traceback. Reactivity analyisis. Dream Plot? 
Maybe base on proof that only O(n) probable pairs in a folding.

* Introduction
** want to fold to predict biological function
** The turner model of RNA structure
*** Notes
- Old models / historical notes
- Current model

- From Mathew's paper: closest structure of 750 generated suboptimal
  has 86.1% of pairs correct and energy 4.8% higher than MFE, all
  together the structures contain 97.1% of known base pairs

- where did Mathews get his data for his 99 paper, accuracy? Does Ye
  Ding's stochastic traceback work better?
*** Citations
Mathews, D. H., Sabina, J., Zuker, M., & Turner,
D. H. (1999). Expanded sequence dependence of thermodynamic parameters
improves prediction of RNA secondary structure. Journal of molecular
biology, 288(5), 911-940.

Xia, T., SantaLucia, J., Burkard, M. E., Kierzek, R., Schroeder,
S. J., Jiao, X., Cox, C. & Turner, D. H. (1998). Thermodynamic parameters
for an expanded nearest-neighbor model for formation of RNA duplexes
with Watson-Crick base pairs. Biochemistry, 37(42), 14719-14735.

*** Writing

The current free energy model of RNA is the result of evolution from
simple model. In the first iterations of the RNA, energy would be
determined by counting hydrogen bonds of cannonically paired. This
would mean that GC pairs are given three units, AU and GU pairs are
both given 2 [TODO: this is almost a quote from turner model paper,
not sure if I could word it differently, what to do?]. This was a
useful model to use as a baseline, and indeed it was used to design
the first minimum free energy algorithm [TODO: cite?]. However, it was
not very accurate, on average only 20.5% of known base pairs are
correctly predicted, and later energy models would use it as a control
for the hypothesis that they increased secondary structure prediction
accuracy (Mathews et al 1999).

Indeed, much improvement was made over the hydrogen bond model by
expanding it to include what are called sequence dependent
parameters. RNA is a polymer, something that bends and is flexible,
and that bending costs energy. Many of the nucleotides in a given RNA
sequence are not going to be paired to another base, and the energies
contributed by these bases as they make up the loops of the secondary
structure are going to be nonzero (unlike in the hydrogen bond
model). In fact, the energies of these loop regions are experimentally
found to be very different depending on what letters make up the
subsequence that defines the loop [Todo: find citation in Mathews
paper]. Thus, what the Turner model does is find the energies of all
the loop regions and add them up. Because the energy model treats the
loop energies as independent of one another it is called a (or the)
nearest neighbor model for RNA [TODO: this may not be precisely right,
consult prof aalberts].

[Todo: loop region figure]

The energy of a loop is dependent on what type of loop it
is. Different loops have different number of enclosing pairs, and this
has consequences in the energy model. For example, a base pair stack,
also called a helical region, is where we have two bases that are
adjacent to each other pairing to two other bases that are also
adjacent to each other. A general internal loop happens when there are
one or more unpaired bases in between the would-be adjacent base pairs
(no other pairs in between). An internal loop has a completely
different energy model compared to a helical region, even though they
are very similar. A multiloop can happen if we have a loop that is
enclosed by more than 2 base pairs, and this has a different energy
model still. In addition to these terms, energies associated with
unpaired bases next to paired bases, called dangling bases, are
included as well. Also a penalty for helices ending in AU's and
general miscellanous terms as more papers were written and more
energies were duct taped into the model [TODO: include kinder
wording]. The specifics of the energy calculations for different loops
are included in the following paragraphs, including how they are
derived from experiments.

\section{UV Melting Experiments}

The thermodynamic behavior of an RNA strand can be determined by
subjecting it to melting curve analysis. When a folded RNA strand
denatures, or unfolds because it is heated, its absorbance of UV
radiation changes. A physical model of this melting process can be
developed to interpret these curves.

\begin{equation}
\Delta G = \Delta H + T \Delta S
\end{equation}

\begin{equation}
T_M^{-1} = \frac{R}{\Delta H} \log{(C_T/a)} + \frac{\Delta S}{R}
\end{equation}

The free energy of a loop structure, or rather its $\Delta G$ relative
to the unfolded state,

\paragraph{Stacked Pairs}

The energy parameters for stacked pair loops were computed in a series
of optical melting experiments (estimating parameters by UV
absorbtion) by Xia et al (1998). For each combination of 2 sets of 2
paired bases, the change in energy at 37 Kelven was computed by
fitting $\Delta H$ and $\Delta S$ to the data. [Todo: decide whether
to have an in depth discussion of this]

For GU, a non-cannonical base pair that happens nontheless, the free
energy is calculated by subtracting the free energy of a CGUACG strand
from the free energy of a CGUUGACG strand, both of whose free energies
are determined by optical melting experiments.


\paragraph{Dangling ends and terminal mismatches}

[TODO: read serra & turner 1995]

bases adjacent to GU pairs are treated the same as bases adjacent to AU pairs

\paragraph{Hairpin loops}

The energy function for a hairpin loop is a similar table lookup.

[TODO: finish this]

- Tetraloop bonus

\paragraph{Bulge loops}

\paragraph{Internal loops}
- 2x2 tandem mismatches
- 2x1 internal loops
- 1x1 (single mismatch


** thermodynamics
** MFE vs clusters
** Robustness of RNA function to mutations (one of the list of unsolved problems in biophysics on Wikipedia)
* Calculating the partition function 
** McCaskill's algorithm, description
* Stochastic Traceback
** description of algorithm
* Improvements of Stochastic straceback
** O(n) probable states (proof?)
** Notes
** Citations
Ding, Y., Chi Yu Chan, and Charles E. Lawrence. "RNA Secondary
Structure Prediction by Centroids in a Boltzmann Weighted Ensemble."
RNA 11.8 (2005): 1157-166. Web.

Ding, Ye, and Charles E. Lawrence. "A Statistical Sampling Algorithm
for RNA Secondary Structure Prediction." Nucleic Acids Research 31.24
(2003): 7280-301. Web.

Wuchty, Stefan, Walter Fontana, Ivo L. Hofacker, and Peter
Schuster. "Complete Suboptimal Folding of RNA and the Stability of
Secondary Structures." Biopolymers 49.2 (1999): 145-65. Web.

Zuker, Michael. "On Finding All Suboptimal Foldings of an RNA
Molecule." Science 244.4900 (1989): 48-52. Web.
** Writing

\section{Introduction}

The stochastic traceback algorithm was introduced by Ye Ding and
Charles Lawrence (2003) as a means to explore the energy landscape of
RNA by sampling structures according to their Boltzmann
probabilities. This was important because the minimum free energy
structure was very sensitive to errors in the parameters of the free
energy model, and although algorithms existed for generating
suboptimal structures, they either sampled a very limited set of
states (Zuker 1989), or had exponential runtime and did not correspond
to the physical ensemble of states (Wuchty et al 1999).

The method uses the partition function algorithm as a forward-fill
step, then it traces back over the contents of the tables allocated
during that algorithm. Specifically, the tables $Q(i,j)$, $Q'(i,j)$,
etc. now contain information about the conditional probabilities of
bases pairing. The general principle of the backwards trace is that,
presented with several possibilities for the structure along a
sequence from $i$ to $j$, the sampling probability for a case is the
contribution to the partition function by that case's partition
function. 

[TODO: figure of stochastic traceback algorithm]

The specific algorithm requires two stack data structures. A stack can
be thought of as a literal "stack", like papers stacked on a desk,
except instead of paper their are items of data. There are two basic
operations, one to put an item on the top of the stack, and another to
retrieve an item off the top. These are called "push" and "pop"
operations, respectively, in Computer Science. The data items we will
be pushing on to the first stack, A, are of the form $\{(i,j), b\}$
where $i$ and $j$ are indexes along the strand and $b$ is either
$True$ if we have determined that $i$ and $j$ are paired, or $False$
otherwise. The second stack, B, is where we'll collect pairs and
unpaired bases for one sample.

The initialization of the algorithm is to push $\{(1, n), False\}$
onto the stack. From there the algorithm repeats the following steps:

\begin{enumerate}
\item Pop an element, $\{i, j, b\}$ off stack A.
\item Case b of $False$:
\begin{enumerate}
\item Pick a $(k, l)$ where $i \leq k < l \leq j$ which is to be the rightmost pair on the segment, with the appropriate probability
\item Push $\{(i, k-1), False\}$ onto stack A, because the structures to the left of $(k,l)$ are not yet determined
\item Push $\{(k, l), True\}$ onto stack A, because we need to determine what type of loop $(k,l)$ encloses
\item Push $(k,l)$ onto stack B as a pair
\item Push all $m$ such  that $l < m \leq j$ onto stack B as unpaired bases, as $(k,l)$ is the rightmost pair
\end{enumerate}
\item Case b of $True$:
\begin{enumerate}
\item Choose what type of loop $(i,j)$ is from \{HAIRPIN, STACK, BULGE/INTERIOR, MULTI-LOOP\} with the appropriate probability
\item Push the appropriate elements onto the stack for that loop type, see figure.
\end{enumerate}
\item If stack A is empty, the pairs and unpaired bases in stack B become a sampled structure. Reinitialize for additional samples.
\end{enumerate}

In the preceding algorithm, I have reference the "appropriate
probability" for each of the different choices. As stated before,
these are the contributions to the partition function by these
cases. In the framework of UNAfold, with the matrices $Q(i,j)$,
$Q'(i,j)$, etc., the specific probabilities would be:

[TODO: note these are pretty much taken from Markham's thesis, but they are accurate, sooo?]

\begin{equation}
P_k(i,j) = \frac{\left ( Q(i, k-1) + e^{-\frac{b(k-i)}{RT} }\right ) Q^1(k, j)}{Q(i,j)}
\end{equation}

which is the probability to pick any $k$ for our rightmost pair
$(k,l)$, where $i \leq k < j$. Note that when summed over all values
of $k$, the top becomes the definition of $Q(i,j)$, therefore these
probabilities sum to 1.

\begin{equation}
[TODO: clarify equations with Aalberts]
\end{equation}

\begin{equation}

\end{equation}

\begin{equation}

\end{equation}

\begin{equation}

\end{equation}

The probabilities are normalized and sampled from to output the first
pair. From then on, if a pairs $(h,l)$ is chosen, the algorithm
chooses the type of structure that $(h,l)$ encloses with the
probabilities:

\begin{equation}

\end{equation}

\begin{equation}

\end{equation}

\begin{equation}

\end{equation}

\begin{equation}

\end{equation}

\begin{equation}

\end{equation}

The algorithm continues from there on in a similar fashion, choosing
from each case according to their partition function. Our innovation
is to reduce the number of unnecesary computations. The partition
function has already been calculated, so we already know which bases
that might be paired and which bases are almost certainly not
paired. By only checking the pairs that we know can happen, we see a
large speedup.

\section{Motivation}

In the past 10 years, the stochastic traceback algorithm has become an
increasingly central part of RNA secondary structure prediction
algorithms (Ding et al 2005, [TODO: cite more]). This is because they
present many advantages over the minimum free energy prediction. It
can be shown that the minimum free energy state, even though it is the
most probable state, can still have astronomically unlikely
probabilities on average for typical strands of reasonable length
([TODO: cite, figure]). The more important concept in understanding
the physical behavior of an RNA strand is therefore the overall shape
of the energy landscape. Althogh the probability of any individual
structure might be infinitesimally small, there can be shown to be
relatively few large basins containing clusters of similar foldings.
The consensus structures and the difference between the consensus
structures of these basins define the function of the RNA molecule.

The way the stochastic algorithms probe that is by providing
structures to group into these basins, and since the stochastic
traceback algorithm samples states with the exact probability defined
by the partition function, we know that the macrobehavior of these
samples match what we would probably see in reality. There is one
catch and that is statistical error. However, the error can be reduced
and the landscape can be further explored the more stochastic samples
we make.

The need to sample large numbers of secondary structures makes a
speedup very convenient, and that is what motivates our current
expedition.

\section{Methods}

Taking advantage of the empirical fact that the number of probable
base pairs for an RNA strand tend to grow very slowly, we can restrict
our traceback to only explore bases that we know can pair with one
another.

\section{Results}

As one can see from the tables, the speedup is enormous. For randomly
sampled sequences up to lengths in the thousands, the old stochastic
timing grows quadratically, while the new method flatlines below it.

[TODO: add speedup figure]

A good question to ask would be, how do we know that this new
algorithm is outputting structures with the correct
probabilities. Verification plots here attempt to answer that
question.

[TODO: add verification plot]

What we would expect to see from these plots, is that for a given
base, we would expect to see it pair with other bases with
probabilities given by the partition function as one can see. Of
course there is sampling error, so each bin represents a sampling from
a Bernoulli distribution. For n^2 samples, we would expect [Todo: find
out what error we expect] error. The number of samples that violate
the bounds, do not deviate much from what we would expect from doing
$n^2$ experiments, so I think we can confidently say that the new
algorithm is making the correct computation.

* Clustering and Nestor
** Notes
- Motivation for clustering
- BP method of clustering
- Description of Nestor/algorithm
- Description / analysis of output
** Writing

\section{Motivation}

Given that we know, for any given RNA strand, the probability of an
individual state is very low [TODO: reference section], a much more
important computation is the overall shape of the strand's free energy
landscape. Even if the probability of an individual state is low, if
we "integrate" over a basin of free energy, the probability of that
set of states could be something tangible.

In the past 10 years, several groups have started to explore this
concept. There are two approaches, in general, to define basins and
classify structures into them. The first class of methods defines the
basins from the top-down: given a number of stochastically sampled
structures, we divide them into groups based on some kind of distance
metric. These methods tend to be very similar to typical clustering
algorithms used in computer science and data analysis.

Another approach is to start at local minima and climb up the energy
barriers between minima using the metropolis-hastings algorithm to
maintain the correct probabilities according to the partition
function. These methods can be used to accurately compute the energies
of the transition states between local minima and these can tell you
the kinetics of the structure. This technique was developed by [TODO:
find Vienna people and cite them].

 Enabled by their stochastic sampling algorithm Ye Ding and
Charles E. Lawrence clustering algorithms. [TODO: evaluate this].

* Reactivity Experiments
** Introduction
   
*** Predicting the output of pairs is good, but do they actually relate to experiments?
    
*** List of methods to confirm the predictions of RNA (??? I don't know any others, ask aalberts)
    
*** one way we studied was reactivity, specifically mutate and map experiments
    
*** we like these because not only can they confirm or deny our binding predictions, but also the predictions cluster probability.
    
*** (actual section)

What good is any theoretical system unless its results can be tested?
A good theorist must find real world evidence of her theories. In
physics this usually amounts to finding a measurable quantity and
setting up an experiment to properly measure it. This is not as
straightforward as it sounds, as the Williams students who take
Applications of Quantum Mechanics learn for example, a lot of care
must be taken to ensure that a single photon experiment actually has
one photon going through at a time. For a theoretical biologist this
task is exascerbated by environment in which the most important
measurements must take place: in vivo. For example, the partition
function of an rna strand describes its statistical properties in
thermal equilibrium. However, the living cell is certainly not in
thermal equilibrium so there will always be an underlying uncertainty
associated with this fact. Despite this, it could be true that an rna
strand floats around in a state very close to thermal equilibrium
interupted periodically by interactions with other proteins which
would represent large deviations from a thermal equilibrium, but could
be modeled as the original rna strand in equilibrium with some bases
blocked. This is one situation that can be modeled by the mutate and
map experiments run by Rhiju Das at Stanford.

These experiments comprise of [MUTATE PROCESS] and SHAPE analysis.

- mutate and map expriements
 


** description of experiment (electropherogram trace, the gels...)

*** SHAPE: Selective 2'-hydroxyl acylation analyzed by primer extension, quantitative RNA structure analysis at single nucleotide resolution [reference orignal paper]

*** ... how it works

*** RNAstructure pseudoenergy term [reference Dave Mathews]
*** Mutate and Map experiments




** Methods

*** Notes
**** Getting the Data: Rdat files from rmdb.stanford.edu (mutate and map data)

**** Normalize the reactivity data to probabilities

**** Fit clusters using gradient decent 

**** Comparison to Nestor results

*** Figures

- need figure to describe fermi mapping process

- reactivity distribution figure

*** Writing

[Pretty rudimentary description of Das's process] Das Lab at Stanford
perform chemical mapping experiments on RNA molecules. An RNA strand
of interest is selected and is from there on called the wildtype
strand (abbreviated WT). Then for each nucleotide in the strand a
mutant is created switching out that particular base with its Watson
and Crick opposite. This is intended to perturb the energy landscape
in such a way that dominant loops may become less prominent and other
foldings become more stable. SHAPE analysis is then done on each
strand to prob which bases are paired and which are not.

Data was obtained in the form of RDat files from Stanford's RNA
mapping database. SHAPE reactivity is extracted from these files for
the WT and each of its mutants. To normalize the reactivity trace of a
strand to a probability on $[0, 1]$ first the partition function is
calculated for this strand, then probability of each base being paired
is computed using the formula

$$ base pair formula ,$$

and finally these probabilities are rank sorted and fitted to a fermi
distribution using a least squares gradient decent fit [figure
here]. We believe that the measured reactivity should relate
[correlate, correspond?] to the probability that a base is unpaired,
so the reactivities are reverse rank sorted and mapped to the fermi
distribution found by our fit.

From here, using the assumption that each mutation changes the
relative energies of each macrostate without changing their internal
structures, we fit this data to a model of $k$ clusters each with $n$
nucleotide probabilities, with then $k*(n+1)$ cluster
probabilities. Therefore we have a model with $k(2*n + 1)$ paramters
fitting to $n*(n+1)$ data entries. A boxed gradient decent is used to
minimize a cost function:

$ Cost function $

This fit results in $k$ fitted clusters with $k*(n+1)$ cluster
probabilities.

These fitted clusters are compared to $k$ nests generated by
Nestor. The nests are created using the methods desribed in [Nestor
chapter] for each strand. Since these nests are created independant of
any other strands, nests for different strands must be matched to each
other in order to compare to the fitted clusters.

[paragraph on the matching process, still investigating]

Once these matches are made we can compare the cluster vs nest
probabilites for the WT and each mutant and see how they correlate, as
well as investigate other clusters that may be found.

** Results
*** notes

**** reactivity directory
I need a place to have a "consolidated experiment - reactivity
directory.

In it I need: HOBIST_SHP_003.rdat, to get the reactivity data

reactLS.R for the gradient decent fit - must be modified to do the
fermi stuff

ONE SCRIPT to do ENTIRE experiment

I need to compute the partition function for each several times

What is the experiment?  - take a strand, make it's mutants, get the
  reactivities for each - get the Pi's for the mutant using partition
  function - fit the fermi distribution using R, for each!  ---- are
  these the same for each strand?  - map their reactivities to their
  fermi distributions - do the cluster fit - Nestor each strand, match
  the clusters, note any anomalous clusters - with each cluster
  matched, plot the probabilities of each according to nestor and
  according to the cluster

*** writing



    
** comparison to other methods?

* Partition Function clustering 

** Clustering, without statistical error
** Can be done in O(n^2), same speed as stochastic traceback
** What does it tell us about the energy landscape?


* Improvements to Partition function
** hopefully got down to O(n^2)
** Notes
Need to:

- standardize notation - write an introduction summarizing the goal of
  computing the parition function [check] - note the assumptions about
  the internal loop that lead us to an O(n^3) algorithm. [check?]  -
  talk about energy models for internal loop, multi loop [should be in
  introduction] - write introduction - fill in the RNAstructure
  recurrence relation - fill in our simplified recurrence relation -
  get results - write results
** Writing

\section{Introduction}

As a quick review, the partition function for a thermodynamic system
of fixed volume, in contact with an environment with temperature $T$,
is

\begin{equation} Z = \sum_s e^{E(s)/ RT } \end{equation}

where $s$ denotes a particular state of the system, $E(s)$ is the
energy of that state, and $RT$ is the gas constant multiplied by the
temperature, specified above. Each particular term in the sum is
called that state's Boltzmann factor. The probability of a state is
then said to be its Boltzmann factor divided by the partition
function, or

\begin{equation} P(s) = \frac{e^{E(S)/RT}}{Z}.  \end{equation}

For an RNA molecule, we want to compute the probability of a
particular folding or group of foldings, so we treat it as a
thermodynamic system and sum up the energies of each state, which is a
particular folding. The energy that we assign to an RNA folding is
determined by the Turner Free energy model, mentioned in the
introduction. According to this model, the energy of an RNA folding is
the sum of the energies of the loops that are created by the
folding. These energies are added, for the most part, linearly. This
means if the partition function for some small segment of the strand
is computed, it will have the same contribution to the partition
function of any larger segment that contains it. So we can spare
ourselves from enumerating every single folding by using an approach
that saves the results of these sub-computations in a table, such as
dynamic programming.

The dynamic programming algorithm for computing the partition function
of an RNA strands has several versions. If you ignore psuedoknots, and
if you make an approximation that internal loops will never exceed a
certain length, there is a general agreement that the fastest
algorithm runs in $O(n^3)$, where $n$ is the length of the strand. We
believe that we can streamline this computation even more, taking
advantage of the fact that empirically, the number of probable base
pairs of a strand of length $n$ seems to grow like $n$, not
$n^2$. This is the same result we used to speed up the stochastic
traceback algorithm and [TODO: see if this actually works].

\section{Motivation}

In certain situations, such as partition function clustering, the
partition function is computed and recomputed several times. If the
partition function takes on the order of hours or days to compute,
this can make partition function clustering a bad option. However in
these situations it is also true that the partition function is
recomputed with almost the same properties, just certain pairs
restricted. This motivates a method of computing the partition
function using a known pairs heueristic to prune away unneccesary
computation.

This concept has already been implemented to great success in the
stochastic traceback algorithm. We've been able to show via experiment
that the partition function only admits roughly $O(n)$ pairs with
probabilities above thresholds around the machine precision limit. If
we have the partition function already computed, we can recompute it
by only adding in pairs that have sufficient probability. We can also
extend this method: if a good heuristic appears in the future, one
that can eliminate a large number of pairs, while being
computationally cheap, we should be able to use the results to speed
up the partition function computation.

\section{Computation}

The standard way of computing the partition function involves filling
out a table where the $(i,j)$ member represents the partition function
for the substrand from base $i$ to base $j$. Because the energy model
for RNA is (mostly) linear, the partition function from $i$ to $j$ can
be expressed as a function of nearby members of this table. This
function is the recurrence relation for the partition function of
RNA. Because the free energy model is so complicated and has gone
through many iterations, differenct RNA folding software packages
implement different versions of the recurrence relation, and they vary
widely in complexity.

The definitive representation of the recurrence relation for RNA was
formulated in 1990 by J.S. McCaskill in his landmark paper \emph{The
Equilibrium Partition Function and Base Pair Binding Probabilities for
RNA Secondary Structure} [TODO: cite?]. The formula is also presented
better and explained well by a later paper by Dirks and Pierce in 2003
(Dirks & Peirce 2003). Starting at the outermost layer of this
relation, the formula for the partition function of the strand from
base $i$ to base $j$ is:

\begin{equation} Q(i,j) = 1 + \sum_{i \leq d < e \leq j}Q(i, d - 1)
Q^b(d, e) \end{equation}

The theory behind this formula is that the partition function is a sum
of the empty state (the first term, 1) and the state with at least 1
pair, the furthest pair to the right being pair $(d,e)$. The term
$Q^b(d,e)$ is the partition function assuming that base $d$ and base
$e$ are paired. This function has the following recursion relation:

\begin{equation} Q^b(i, j) = e^{-\frac{\text{Hairpin}(i,j)}{RT}} +
\sum_{i \leq d < e \leq j} e^{\frac{\text{Interior}(i, d, e,
j)}{RT}}Q^b(d,e) + \sum_{i \leq d < e \leq j} Q^m(i + 1, d - 1)Q^b(d,
e) e^{-\frac{\alpha_1 + 2\alpha_2 + \alpha_3(j-e-1)}{RT}}
\end{equation}

The theory behind this formula is that the partition function for a
strand assuming $i$ and $j$ are paired includes 3 cases:

\begin{enumerate}

\item

There are no bases paired between $i$ and $j$, the loop is a hairpin
and uses the energy function for a hairpin loop, we call
$\text{Hairpin}(i,j)$, which consists of data table lookups.

\item There is an internal loop between $i$ and $j$ and a second pair
$d$ and $e$. This uses a different energy model, we call
$\text{Internal}(i,j)$ and also consists of data table lookups.

\item There is a multiloop formed by the pair $i$ and $j$, which must
be carefully accounted for using a special model for multiloops.

\end{enumerate}

The multiloop partition function, $Q^m(i, j)$ is the last piece of the
puzzle. The formula is:

\begin{equation} Q^m(i, j) = \sum_{i \leq d < e \leq j}
e^{-\frac{\alpha_2 + \alpha_3(d-i) + \alpha_3(j-e)}{RT}} Q^b(d,e) +
Q^m(i, d - 1)Q^b(d, e) e^{-\frac{\alpha_2 + \alpha_3(j-e)}{RT}}
\end{equation}

In english, this just means we sum up all the ways to just have 1
pair, and then all the ways to have more than one pair. The case with
no pairs is not included, as in the original recursion in $Q^b$,
$Q^m(i+1, d-1)Q^b(d,e)$ must yield at least 2 pairs. Since $Q^b$ makes
one, then $Q^m$ must make at least 1.

For example, the UNAFold software package implements a particularly
hairy recurrence relation. Define $Q(i,j)$ as the partition function
from $i$ to $j$, $Q'(i,j)$ to be the partition function from $i$ to
$j$, assuming $i$ and $j$ are paired, and define $Q^1(i,j)$ to be the
partition function from $i$ to $j$, assuming exactly 1 pair happens on
that interval, and that pair happens with base $i$. The recurrence
relation is therefore

[recurrence relation]

Note the terms $Z_{ND}$, $Z_{3'D}$, $Z_{5'D}$, and $Z_{DD}$ are extra
free energy terms corresponding to 'dangle energies' which are the
results of an experiment later implemented in the model to improve it
from the standard energy model. In addition there are AU penalty terms
appended to where pairs are made, as AU and GU pairs have penalties
associated with forming. These additional energy terms improve the
model's predictive ability and bring the model closer to the "truth",
however it unfortunately makes the partition function seem very
threatening.

Our new partition function relation has the following theory behind
it: Assume we have the functions $I : B \to \{B\}$ and $J : B \to
\{B\}$ that return the set of all probably pairs for a base $i$ or a
base $j$, respectively. The recurrence relation can be reformulated in
the following way:

[new recurrence relation]

Note that for $Q$ and in many places for $Q'$, instead of a sum over
the known $k$ that could possibly begin a leftmost pair, we see a
double sum. One of them over $k$ that could end a leftmost pair, and
this sum is limited to a certain length below $j$. This is just making
the same assumption that the internal loop computation makes: there
are not arbitrarily long strands without base pairs, after a certain
number of bases it becomes overwhelmingly more likely to make a base
pair that we can virtually ignore the energy of the the cases of
length beyond a certain $L$.

As for the seocnd sum, since the number of probable pairs for a base
$i$ has been shown empirically to be roughly constant, regardless of
length, the second sum is essentially constant. What this all means is
that all $O(n^2)$ computations of $Q(i,j)$'s are roughly constant
time. This means that the overall algorithm is $O(n^2)$, an
improvement over the previous algorithms asymptotic bound by and order
of $n$!

\section{results}

* Further Improvement
** pseudoknot 

* Conclusion



\end{verbatim}



\end{document}
